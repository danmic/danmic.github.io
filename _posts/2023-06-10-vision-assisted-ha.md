---
layout: post
title: "A Vision-Assisted Hearing Aid System Based on Deep Learning"
date: 2023-06-10
excerpt: "Michelsanti D., Tan Z.-H., Rotger-Griful S., Jensen J."
tags: [Audio-visual, hearing aids, beamforming, deep learning]
comments: false

---

### Authors

**Michelsanti D.**, [Tan Z.-H.](http://kom.aau.dk/~zt/), [Rotger-Griful S.](https://sites.google.com/site/sergirotger/), [Jensen J.](http://kom.aau.dk/~jje/)

### Workshop

ICASSP 2023 Workshop - AMHAT 2023: Advances in Multimodal Hearing Assistive Technologies

### Abstract

Audio-visual speech enhancement (SE) is the task of reducing the acoustic background noise in a degraded speech signal using both acoustic and visual information. In this work, we study how to incorporate visual information to enhance a speech signal using acoustic beamformers in hearing aids (HAs). Specifically, we first trained a deep learning model to estimate a time-frequency mask from audio-visual data. Then, we apply this mask to estimate the inter-microphone power spectral densities (PSDs) of the clean and the noise signal. Finally, we used the estimated PSDs to build acoustic beamformers. Assuming that a HA user wears an add-on device comprising a camera pointing at the target speaker, we show that our method can be beneficial for HA systems especially at low signal to noise ratios (SNRs).

[Full text](https://ieeexplore.ieee.org/abstract/document/10193370) [Poster](https://github.com/danmic/danmic.github.io/raw/master/assets/img/poster_amhat.pdf)  